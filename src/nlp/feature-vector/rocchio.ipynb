{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import display\n",
    "# display(pd.Dataframe(data))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi\n",
    "from pprint import pprint\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "from future.utils import iteritems\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "raw_keyword = ['글로벌역량', '능동', '도전', '성실', '소통', '인내심', '정직', '주인의식', '창의', '팀워크']\n",
    "\n",
    "# tf-idf값 불러오는 과정\n",
    "X = pd.read_csv('dataset/results/large_vector_X.csv', header=None)\n",
    "X = np.array(X)\n",
    "print(X)\n",
    "print(X.shape)\n",
    "print(type(X))\n",
    "\n",
    "# 학습 단어(feature) 불러오는 과정\n",
    "f = open('dataset/results/large_vector_X_features.csv', 'r', encoding='utf-8')\n",
    "reader = csv.reader(f)\n",
    "features = list()\n",
    "\n",
    "for row in reader:\n",
    "    features.append(row[0])\n",
    "    \n",
    "# 불용어리스트 불러오는 과정\n",
    "f = open('dataset/stopwords/stopwords.csv', 'r', encoding='utf-8')\n",
    "reader = csv.reader(f)\n",
    "stopwords = list()\n",
    "\n",
    "for row in reader:\n",
    "    stopwords.append(row[0])\n",
    "\n",
    "print(type(features))\n",
    "\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def read_data(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        data = f.read()\n",
    "        # remove_quotes\n",
    "        data = data.replace(\"‘\", \" \")\n",
    "        data = data.replace(\"’\", \" \")\n",
    "        data = data.replace(\"“\", \" \")\n",
    "        data = data.replace(\"”\", \" \")\n",
    "        data = data.replace(\"`\", \" \")\n",
    "        data = data.replace(\"\\'\", \" \")\n",
    "        data = data.replace(\"\\\"\", \" \")\n",
    "    return data\n",
    "\n",
    "def tokenizer(raw, pos=[\"Noun\",\"Verb\"], stopword=stopwords):\n",
    "    return [\n",
    "        word for word, tag in okt.pos(\n",
    "            raw, \n",
    "            norm=True,   # normalize 정제 과정\n",
    "            stem=True    # stemming 정제 과정\n",
    "            )\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "\n",
    "def read_data(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "        one_data = [json_data[i] for i in json_data]\n",
    "    return one_data\n",
    "    \n",
    "with open('dataset/resumes/educe_CJ_570.json', encoding='utf-8') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "resume = ''\n",
    "for i in json_data:\n",
    "    resume += i['document']\n",
    "    \n",
    "print(len(resume))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
