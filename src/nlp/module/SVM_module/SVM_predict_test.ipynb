{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import joblib\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openStopword():\n",
    "    # 불용어리스트\n",
    "    f = open('dataset/stopwords/stopwords.csv', 'r', encoding='utf-8')\n",
    "    reader = csv.reader(f)\n",
    "    stopwords = list()\n",
    "\n",
    "    for row in reader:\n",
    "        stopwords.append(row[0])\n",
    "\n",
    "    return stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(raw, pos=[\"Noun\",\"Verb\"], stopword=openStopword()):\n",
    "    return [\n",
    "        word for word, tag in okt.pos(\n",
    "            raw, \n",
    "            norm=True,   # normalize 정제 과정\n",
    "            stem=True    # stemming 정제 과정\n",
    "            )\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "능동\n",
      "능동\n",
      "팀워크\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    okt = Okt()\n",
    "    keyword_names = ['글로벌역량', '능동', '도전', '성실', '소통', '인내심', '정직', '주인의식', '창의', '팀워크']\n",
    "\n",
    "    vectorize = TfidfVectorizer(\n",
    "        ngram_range=(1,2),\n",
    "        tokenizer=tokenizer,\n",
    "        max_df=0.95,\n",
    "        min_df=0,\n",
    "        sublinear_tf=True\n",
    "    )\n",
    "\n",
    "    filename = 'SVMmodel.pkl'\n",
    "    clf_from_pickle = joblib.load(filename)\n",
    "\n",
    "\n",
    "    def SVMpredict(text):\n",
    "        result = clf_from_pickle.predict([text])\n",
    "        return keyword_names[result[0]-1]\n",
    "\n",
    "\n",
    "    print(SVMpredict(\"개정안에 따르면, 앞으로 산업기술 R&D는 ‘신속한 기술개발’을 우선 고려한다. 이를 위해 연구수행자는 ‘기존 기술의 도입을 통한 기간 단축 및 사업비 절감방안’을 사업계획서에 반드시 포함하도록 했고, 신규평가에서도 이 내용을 검토할 예정이다. 이를 통해 산업기술 R&D 전반의 개발 속도가 단축돼 4차 산업혁명 시대에 급변하는 외부환경 변화에 적기대응할 수 있는 제도적 기반을 갖추게 될 전망이다.\"))\n",
    "    print(SVMpredict(\"오늘도 캡스톤을 하러 학교에 남았다\"))\n",
    "    print(SVMpredict(\"또한, 산업의 난제를 푸는 ‘도전적 프로젝트(알키미스트 프로젝트)’의 시행을 위해 기획부터 평가방식까지 사업추진 방식을 전면 개선했다. 알키미스트 프로젝트는 6월부터 시범사업(국비 100억원 규모)을 추진하고, 2020년부터는 과기부와 협업과제를 발굴하여 본격 시행될 예정으롤 예비타당성 조사를 추진하고 있다.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (capstone)",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
